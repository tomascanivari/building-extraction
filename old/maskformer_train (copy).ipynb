{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bac73592",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f449bf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu128\n",
      "Collecting torch\n",
      "  Downloading https://download.pytorch.org/whl/cu128/torch-2.9.0%2Bcu128-cp310-cp310-manylinux_2_28_x86_64.whl (900.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m900.9/900.9 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting torchvision\n",
      "  Downloading https://download.pytorch.org/whl/cu128/torchvision-0.24.0%2Bcu128-cp310-cp310-manylinux_2_28_x86_64.whl (8.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.0/8.0 MB\u001b[0m \u001b[31m60.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting torchaudio\n",
      "  Downloading https://download.pytorch.org/whl/cu128/torchaudio-2.9.0%2Bcu128-cp310-cp310-manylinux_2_28_x86_64.whl (2.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m49.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cudnn-cu12==9.10.2.21\n",
      "  Downloading https://download.pytorch.org/whl/nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl (706.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m706.8/706.8 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting triton==3.5.0\n",
      "  Downloading https://download.pytorch.org/whl/triton-3.5.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (170.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m170.3/170.3 MB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nvshmem-cu12==3.3.20\n",
      "  Downloading https://download.pytorch.org/whl/nvidia_nvshmem_cu12-3.3.20-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (124.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.7/124.7 MB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nccl-cu12==2.27.5\n",
      "  Downloading https://download.pytorch.org/whl/nvidia_nccl_cu12-2.27.5-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (322.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.3/322.3 MB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cufft-cu12==11.3.3.83\n",
      "  Downloading https://download.pytorch.org/whl/cu128/nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (193.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.1/193.1 MB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-curand-cu12==10.3.9.90\n",
      "  Downloading https://download.pytorch.org/whl/cu128/nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl (63.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.6/63.6 MB\u001b[0m \u001b[31m35.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-nvrtc-cu12==12.8.93\n",
      "  Downloading https://download.pytorch.org/whl/cu128/nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (88.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.0/88.0 MB\u001b[0m \u001b[31m29.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nvjitlink-cu12==12.8.93\n",
      "  Downloading https://download.pytorch.org/whl/cu128/nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (39.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.3/39.3 MB\u001b[0m \u001b[31m45.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting filelock\n",
      "  Downloading https://download.pytorch.org/whl/filelock-3.19.1-py3-none-any.whl (15 kB)\n",
      "Collecting sympy>=1.13.3\n",
      "  Downloading https://download.pytorch.org/whl/sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m58.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.8.90\n",
      "  Downloading https://download.pytorch.org/whl/cu128/nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (954 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m954.8/954.8 KB\u001b[0m \u001b[31m47.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cublas-cu12==12.8.4.1\n",
      "  Downloading https://download.pytorch.org/whl/cu128/nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl (594.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m594.3/594.3 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=4.10.0 in ./building_env/lib/python3.10/site-packages (from torch) (4.15.0)\n",
      "Collecting nvidia-cusparselt-cu12==0.7.1\n",
      "  Downloading https://download.pytorch.org/whl/nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl (287.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m287.2/287.2 MB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nvtx-cu12==12.8.90\n",
      "  Downloading https://download.pytorch.org/whl/cu128/nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 KB\u001b[0m \u001b[31m39.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting jinja2\n",
      "  Downloading https://download.pytorch.org/whl/jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.9/134.9 KB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cufile-cu12==1.13.1.3\n",
      "  Downloading https://download.pytorch.org/whl/cu128/nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m50.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cusolver-cu12==11.7.3.90\n",
      "  Downloading https://download.pytorch.org/whl/cu128/nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl (267.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m267.5/267.5 MB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cusparse-cu12==12.5.8.93\n",
      "  Downloading https://download.pytorch.org/whl/cu128/nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (288.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.2/288.2 MB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting fsspec>=0.8.5\n",
      "  Downloading https://download.pytorch.org/whl/fsspec-2025.9.0-py3-none-any.whl (199 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.3/199.3 KB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.8.90\n",
      "  Downloading https://download.pytorch.org/whl/cu128/nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (10.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m55.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hCollecting networkx>=2.5.1\n",
      "  Downloading https://download.pytorch.org/whl/networkx-3.5-py3-none-any.whl (2.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m54.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting pillow!=8.3.*,>=5.3.0\n",
      "  Downloading https://download.pytorch.org/whl/pillow-11.3.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m62.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting numpy\n",
      "  Downloading https://download.pytorch.org/whl/numpy-2.1.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.3/16.3 MB\u001b[0m \u001b[31m62.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting networkx>=2.5.1\n",
      "  Downloading https://download.pytorch.org/whl/networkx-3.3-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m48.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting mpmath<1.4,>=1.1.0\n",
      "  Downloading https://download.pytorch.org/whl/mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 KB\u001b[0m \u001b[31m26.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting MarkupSafe>=2.0\n",
      "  Downloading https://download.pytorch.org/whl/MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
      "Installing collected packages: nvidia-cusparselt-cu12, mpmath, triton, sympy, pillow, nvidia-nvtx-cu12, nvidia-nvshmem-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, networkx, MarkupSafe, fsspec, filelock, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, jinja2, nvidia-cusolver-cu12, torch, torchvision, torchaudio\n",
      "Successfully installed MarkupSafe-2.1.5 filelock-3.19.1 fsspec-2025.9.0 jinja2-3.1.6 mpmath-1.3.0 networkx-3.3 numpy-2.1.2 nvidia-cublas-cu12-12.8.4.1 nvidia-cuda-cupti-cu12-12.8.90 nvidia-cuda-nvrtc-cu12-12.8.93 nvidia-cuda-runtime-cu12-12.8.90 nvidia-cudnn-cu12-9.10.2.21 nvidia-cufft-cu12-11.3.3.83 nvidia-cufile-cu12-1.13.1.3 nvidia-curand-cu12-10.3.9.90 nvidia-cusolver-cu12-11.7.3.90 nvidia-cusparse-cu12-12.5.8.93 nvidia-cusparselt-cu12-0.7.1 nvidia-nccl-cu12-2.27.5 nvidia-nvjitlink-cu12-12.8.93 nvidia-nvshmem-cu12-3.3.20 nvidia-nvtx-cu12-12.8.90 pillow-11.3.0 sympy-1.14.0 torch-2.9.0+cu128 torchaudio-2.9.0+cu128 torchvision-0.24.0+cu128 triton-3.5.0\n",
      "Collecting datasets\n",
      "  Downloading datasets-4.2.0-py3-none-any.whl (506 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m506.3/506.3 KB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting pandas\n",
      "  Downloading pandas-2.3.3-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (12.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m42.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting pyarrow>=21.0.0\n",
      "  Downloading pyarrow-21.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (42.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.7/42.7 MB\u001b[0m \u001b[31m34.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting multiprocess<0.70.17\n",
      "  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 KB\u001b[0m \u001b[31m54.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: fsspec[http]<=2025.9.0,>=2023.1.0 in ./building_env/lib/python3.10/site-packages (from datasets) (2025.9.0)\n",
      "Requirement already satisfied: packaging in ./building_env/lib/python3.10/site-packages (from datasets) (25.0)\n",
      "Requirement already satisfied: numpy>=1.17 in ./building_env/lib/python3.10/site-packages (from datasets) (2.1.2)\n",
      "Collecting xxhash\n",
      "  Downloading xxhash-3.6.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (193 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.2/193.2 KB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pyyaml>=5.1\n",
      "  Downloading pyyaml-6.0.3-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (770 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m770.3/770.3 KB\u001b[0m \u001b[31m42.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting dill<0.4.1,>=0.3.0\n",
      "  Downloading dill-0.4.0-py3-none-any.whl (119 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.7/119.7 KB\u001b[0m \u001b[31m55.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in ./building_env/lib/python3.10/site-packages (from datasets) (3.19.1)\n",
      "Collecting httpx<1.0.0\n",
      "  Downloading httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.5/73.5 KB\u001b[0m \u001b[31m36.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting huggingface-hub<2.0,>=0.25.0\n",
      "  Downloading huggingface_hub-0.35.3-py3-none-any.whl (564 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m564.3/564.3 KB\u001b[0m \u001b[31m37.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tqdm>=4.66.3\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 KB\u001b[0m \u001b[31m35.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting requests>=2.32.2\n",
      "  Downloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.7/64.7 KB\u001b[0m \u001b[31m30.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting aiohttp!=4.0.0a0,!=4.0.0a1\n",
      "  Downloading aiohttp-3.13.1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (1.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m93.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting certifi\n",
      "  Downloading certifi-2025.10.5-py3-none-any.whl (163 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.3/163.3 KB\u001b[0m \u001b[31m69.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting idna\n",
      "  Downloading idna-3.11-py3-none-any.whl (71 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.0/71.0 KB\u001b[0m \u001b[31m37.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting httpcore==1.*\n",
      "  Downloading httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.8/78.8 KB\u001b[0m \u001b[31m39.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting anyio\n",
      "  Downloading anyio-4.11.0-py3-none-any.whl (109 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m109.1/109.1 KB\u001b[0m \u001b[31m52.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting h11>=0.16\n",
      "  Downloading h11-0.16.0-py3-none-any.whl (37 kB)\n",
      "Collecting hf-xet<2.0.0,>=1.1.3\n",
      "  Downloading hf_xet-1.1.10-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m73.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in ./building_env/lib/python3.10/site-packages (from huggingface-hub<2.0,>=0.25.0->datasets) (4.15.0)\n",
      "Collecting charset_normalizer<4,>=2\n",
      "  Downloading charset_normalizer-3.4.4-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (153 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.6/153.6 KB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting urllib3<3,>=1.21.1\n",
      "  Downloading urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.8/129.8 KB\u001b[0m \u001b[31m34.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pytz>=2020.1\n",
      "  Downloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m509.2/509.2 KB\u001b[0m \u001b[31m76.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.2 in ./building_env/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Collecting tzdata>=2022.7\n",
      "  Downloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m347.8/347.8 KB\u001b[0m \u001b[31m94.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting attrs>=17.3.0\n",
      "  Downloading attrs-25.4.0-py3-none-any.whl (67 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.6/67.6 KB\u001b[0m \u001b[31m33.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting async-timeout<6.0,>=4.0\n",
      "  Downloading async_timeout-5.0.1-py3-none-any.whl (6.2 kB)\n",
      "Collecting aiosignal>=1.4.0\n",
      "  Downloading aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n",
      "Collecting aiohappyeyeballs>=2.5.0\n",
      "  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Collecting frozenlist>=1.1.1\n",
      "  Downloading frozenlist-1.8.0-cp310-cp310-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (219 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m219.5/219.5 KB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting yarl<2.0,>=1.17.0\n",
      "  Downloading yarl-1.22.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (346 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m347.0/347.0 KB\u001b[0m \u001b[31m26.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting multidict<7.0,>=4.5\n",
      "  Downloading multidict-6.7.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (241 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m241.7/241.7 KB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting propcache>=0.2.0\n",
      "  Downloading propcache-0.4.1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (196 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.9/196.9 KB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: six>=1.5 in ./building_env/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in ./building_env/lib/python3.10/site-packages (from anyio->httpx<1.0.0->datasets) (1.3.0)\n",
      "Collecting sniffio>=1.1\n",
      "  Downloading sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Installing collected packages: pytz, xxhash, urllib3, tzdata, tqdm, sniffio, pyyaml, pyarrow, propcache, multidict, idna, hf-xet, h11, frozenlist, dill, charset_normalizer, certifi, attrs, async-timeout, aiohappyeyeballs, yarl, requests, pandas, multiprocess, httpcore, anyio, aiosignal, huggingface-hub, httpx, aiohttp, datasets\n",
      "Successfully installed aiohappyeyeballs-2.6.1 aiohttp-3.13.1 aiosignal-1.4.0 anyio-4.11.0 async-timeout-5.0.1 attrs-25.4.0 certifi-2025.10.5 charset_normalizer-3.4.4 datasets-4.2.0 dill-0.4.0 frozenlist-1.8.0 h11-0.16.0 hf-xet-1.1.10 httpcore-1.0.9 httpx-0.28.1 huggingface-hub-0.35.3 idna-3.11 multidict-6.7.0 multiprocess-0.70.16 pandas-2.3.3 propcache-0.4.1 pyarrow-21.0.0 pytz-2025.2 pyyaml-6.0.3 requests-2.32.5 sniffio-1.3.1 tqdm-4.67.1 tzdata-2025.2 urllib3-2.5.0 xxhash-3.6.0 yarl-1.22.0\n",
      "Collecting evaluate\n",
      "  Downloading evaluate-0.4.6-py3-none-any.whl (84 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 KB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: multiprocess in ./building_env/lib/python3.10/site-packages (from evaluate) (0.70.16)\n",
      "Requirement already satisfied: requests>=2.19.0 in ./building_env/lib/python3.10/site-packages (from evaluate) (2.32.5)\n",
      "Requirement already satisfied: dill in ./building_env/lib/python3.10/site-packages (from evaluate) (0.4.0)\n",
      "Requirement already satisfied: pandas in ./building_env/lib/python3.10/site-packages (from evaluate) (2.3.3)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in ./building_env/lib/python3.10/site-packages (from evaluate) (4.67.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in ./building_env/lib/python3.10/site-packages (from evaluate) (0.35.3)\n",
      "Requirement already satisfied: xxhash in ./building_env/lib/python3.10/site-packages (from evaluate) (3.6.0)\n",
      "Requirement already satisfied: numpy>=1.17 in ./building_env/lib/python3.10/site-packages (from evaluate) (2.1.2)\n",
      "Requirement already satisfied: fsspec[http]>=2021.05.0 in ./building_env/lib/python3.10/site-packages (from evaluate) (2025.9.0)\n",
      "Requirement already satisfied: packaging in ./building_env/lib/python3.10/site-packages (from evaluate) (25.0)\n",
      "Requirement already satisfied: datasets>=2.0.0 in ./building_env/lib/python3.10/site-packages (from evaluate) (4.2.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./building_env/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (6.0.3)\n",
      "Requirement already satisfied: pyarrow>=21.0.0 in ./building_env/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (21.0.0)\n",
      "Requirement already satisfied: filelock in ./building_env/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.19.1)\n",
      "Requirement already satisfied: httpx<1.0.0 in ./building_env/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (0.28.1)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in ./building_env/lib/python3.10/site-packages (from fsspec[http]>=2021.05.0->evaluate) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./building_env/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in ./building_env/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (1.1.10)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./building_env/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./building_env/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2.5.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./building_env/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./building_env/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2025.10.5)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./building_env/lib/python3.10/site-packages (from pandas->evaluate) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./building_env/lib/python3.10/site-packages (from pandas->evaluate) (2025.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./building_env/lib/python3.10/site-packages (from pandas->evaluate) (2.9.0.post0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./building_env/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (25.4.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in ./building_env/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (2.6.1)\n",
      "Requirement already satisfied: propcache>=0.2.0 in ./building_env/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (0.4.1)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in ./building_env/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (5.0.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./building_env/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (6.7.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in ./building_env/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.22.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./building_env/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.8.0)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in ./building_env/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.4.0)\n",
      "Requirement already satisfied: httpcore==1.* in ./building_env/lib/python3.10/site-packages (from httpx<1.0.0->datasets>=2.0.0->evaluate) (1.0.9)\n",
      "Requirement already satisfied: anyio in ./building_env/lib/python3.10/site-packages (from httpx<1.0.0->datasets>=2.0.0->evaluate) (4.11.0)\n",
      "Requirement already satisfied: h11>=0.16 in ./building_env/lib/python3.10/site-packages (from httpcore==1.*->httpx<1.0.0->datasets>=2.0.0->evaluate) (0.16.0)\n",
      "Requirement already satisfied: six>=1.5 in ./building_env/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in ./building_env/lib/python3.10/site-packages (from anyio->httpx<1.0.0->datasets>=2.0.0->evaluate) (1.3.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in ./building_env/lib/python3.10/site-packages (from anyio->httpx<1.0.0->datasets>=2.0.0->evaluate) (1.3.0)\n",
      "Installing collected packages: evaluate\n",
      "Successfully installed evaluate-0.4.6\n",
      "Collecting albumentations\n",
      "  Downloading albumentations-2.0.8-py3-none-any.whl (369 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m369.4/369.4 KB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting albucore==0.0.24\n",
      "  Downloading albucore-0.0.24-py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: numpy>=1.24.4 in ./building_env/lib/python3.10/site-packages (from albumentations) (2.1.2)\n",
      "Collecting pydantic>=2.9.2\n",
      "  Downloading pydantic-2.12.3-py3-none-any.whl (462 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m462.4/462.4 KB\u001b[0m \u001b[31m28.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: PyYAML in ./building_env/lib/python3.10/site-packages (from albumentations) (6.0.3)\n",
      "Collecting scipy>=1.10.0\n",
      "  Downloading scipy-1.15.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (37.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.7/37.7 MB\u001b[0m \u001b[31m33.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting opencv-python-headless>=4.9.0.80\n",
      "  Downloading opencv_python_headless-4.12.0.88-cp37-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (54.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.0/54.0 MB\u001b[0m \u001b[31m46.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting simsimd>=5.9.2\n",
      "  Downloading simsimd-6.5.3-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (1.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m44.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting stringzilla>=3.10.4\n",
      "  Downloading stringzilla-4.2.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl (592 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m592.1/592.1 KB\u001b[0m \u001b[31m40.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting typing-inspection>=0.4.2\n",
      "  Downloading typing_inspection-0.4.2-py3-none-any.whl (14 kB)\n",
      "Collecting pydantic-core==2.41.4\n",
      "  Downloading pydantic_core-2.41.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m64.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=4.14.1 in ./building_env/lib/python3.10/site-packages (from pydantic>=2.9.2->albumentations) (4.15.0)\n",
      "Collecting annotated-types>=0.6.0\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Installing collected packages: simsimd, typing-inspection, stringzilla, scipy, pydantic-core, opencv-python-headless, annotated-types, pydantic, albucore, albumentations\n",
      "Successfully installed albucore-0.0.24 albumentations-2.0.8 annotated-types-0.7.0 opencv-python-headless-4.12.0.88 pydantic-2.12.3 pydantic-core-2.41.4 scipy-1.15.3 simsimd-6.5.3 stringzilla-4.2.1 typing-inspection-0.4.2\n",
      "Collecting git+https://github.com/huggingface/transformers.git\n",
      "  Cloning https://github.com/huggingface/transformers.git to /tmp/pip-req-build-a39s3blp\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers.git /tmp/pip-req-build-a39s3blp\n",
      "  Resolved https://github.com/huggingface/transformers.git to commit 9aab965b1e61d92d402809bd467c317ec464e560\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting safetensors>=0.4.3\n",
      "  Downloading safetensors-0.6.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (485 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m485.8/485.8 KB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in ./building_env/lib/python3.10/site-packages (from transformers==5.0.0.dev0) (3.19.1)\n",
      "Requirement already satisfied: packaging>=20.0 in ./building_env/lib/python3.10/site-packages (from transformers==5.0.0.dev0) (25.0)\n",
      "Requirement already satisfied: numpy>=1.17 in ./building_env/lib/python3.10/site-packages (from transformers==5.0.0.dev0) (2.1.2)\n",
      "Requirement already satisfied: requests in ./building_env/lib/python3.10/site-packages (from transformers==5.0.0.dev0) (2.32.5)\n",
      "Collecting tokenizers<=0.23.0,>=0.22.0\n",
      "  Downloading tokenizers-0.22.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in ./building_env/lib/python3.10/site-packages (from transformers==5.0.0.dev0) (4.67.1)\n",
      "Collecting huggingface-hub==1.0.0.rc6\n",
      "  Downloading huggingface_hub-1.0.0rc6-py3-none-any.whl (502 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m502.0/502.0 KB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in ./building_env/lib/python3.10/site-packages (from transformers==5.0.0.dev0) (6.0.3)\n",
      "Collecting typer-slim\n",
      "  Downloading typer_slim-0.20.0-py3-none-any.whl (47 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.1/47.1 KB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting regex!=2019.12.17\n",
      "  Downloading regex-2025.9.18-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (789 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m789.9/789.9 KB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: hf-xet<2.0.0,>=1.1.3 in ./building_env/lib/python3.10/site-packages (from huggingface-hub==1.0.0.rc6->transformers==5.0.0.dev0) (1.1.10)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./building_env/lib/python3.10/site-packages (from huggingface-hub==1.0.0.rc6->transformers==5.0.0.dev0) (2025.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./building_env/lib/python3.10/site-packages (from huggingface-hub==1.0.0.rc6->transformers==5.0.0.dev0) (4.15.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in ./building_env/lib/python3.10/site-packages (from huggingface-hub==1.0.0.rc6->transformers==5.0.0.dev0) (0.28.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./building_env/lib/python3.10/site-packages (from requests->transformers==5.0.0.dev0) (2025.10.5)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./building_env/lib/python3.10/site-packages (from requests->transformers==5.0.0.dev0) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./building_env/lib/python3.10/site-packages (from requests->transformers==5.0.0.dev0) (2.5.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./building_env/lib/python3.10/site-packages (from requests->transformers==5.0.0.dev0) (3.4.4)\n",
      "Collecting click>=8.0.0\n",
      "  Downloading click-8.3.0-py3-none-any.whl (107 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.3/107.3 KB\u001b[0m \u001b[31m35.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: httpcore==1.* in ./building_env/lib/python3.10/site-packages (from httpx<1,>=0.23.0->huggingface-hub==1.0.0.rc6->transformers==5.0.0.dev0) (1.0.9)\n",
      "Requirement already satisfied: anyio in ./building_env/lib/python3.10/site-packages (from httpx<1,>=0.23.0->huggingface-hub==1.0.0.rc6->transformers==5.0.0.dev0) (4.11.0)\n",
      "Requirement already satisfied: h11>=0.16 in ./building_env/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->huggingface-hub==1.0.0.rc6->transformers==5.0.0.dev0) (0.16.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in ./building_env/lib/python3.10/site-packages (from anyio->httpx<1,>=0.23.0->huggingface-hub==1.0.0.rc6->transformers==5.0.0.dev0) (1.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in ./building_env/lib/python3.10/site-packages (from anyio->httpx<1,>=0.23.0->huggingface-hub==1.0.0.rc6->transformers==5.0.0.dev0) (1.3.1)\n",
      "Building wheels for collected packages: transformers\n",
      "  Building wheel for transformers (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for transformers: filename=transformers-5.0.0.dev0-py3-none-any.whl size=11400108 sha256=143c2a5b35aab0212bceb6f8644c7e8bba07c191ed77c7f9efe1d617d14fa78b\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-yox4eqog/wheels/e7/9c/5b/e1a9c8007c343041e61cc484433d512ea9274272e3fcbe7c16\n",
      "Successfully built transformers\n",
      "Installing collected packages: safetensors, regex, click, typer-slim, huggingface-hub, tokenizers, transformers\n",
      "  Attempting uninstall: huggingface-hub\n",
      "    Found existing installation: huggingface-hub 0.35.3\n",
      "    Uninstalling huggingface-hub-0.35.3:\n",
      "      Successfully uninstalled huggingface-hub-0.35.3\n",
      "Successfully installed click-8.3.0 huggingface-hub-1.0.0rc6 regex-2025.9.18 safetensors-0.6.2 tokenizers-0.22.1 transformers-5.0.0.dev0 typer-slim-0.20.0\n",
      "Requirement already satisfied: huggingface_hub in ./building_env/lib/python3.10/site-packages (1.0.0rc6)\n",
      "Requirement already satisfied: filelock in ./building_env/lib/python3.10/site-packages (from huggingface_hub) (3.19.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./building_env/lib/python3.10/site-packages (from huggingface_hub) (2025.9.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./building_env/lib/python3.10/site-packages (from huggingface_hub) (6.0.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./building_env/lib/python3.10/site-packages (from huggingface_hub) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in ./building_env/lib/python3.10/site-packages (from huggingface_hub) (1.1.10)\n",
      "Requirement already satisfied: packaging>=20.9 in ./building_env/lib/python3.10/site-packages (from huggingface_hub) (25.0)\n",
      "Requirement already satisfied: typer-slim in ./building_env/lib/python3.10/site-packages (from huggingface_hub) (0.20.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in ./building_env/lib/python3.10/site-packages (from huggingface_hub) (4.67.1)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in ./building_env/lib/python3.10/site-packages (from huggingface_hub) (0.28.1)\n",
      "Requirement already satisfied: httpcore==1.* in ./building_env/lib/python3.10/site-packages (from httpx<1,>=0.23.0->huggingface_hub) (1.0.9)\n",
      "Requirement already satisfied: anyio in ./building_env/lib/python3.10/site-packages (from httpx<1,>=0.23.0->huggingface_hub) (4.11.0)\n",
      "Requirement already satisfied: idna in ./building_env/lib/python3.10/site-packages (from httpx<1,>=0.23.0->huggingface_hub) (3.11)\n",
      "Requirement already satisfied: certifi in ./building_env/lib/python3.10/site-packages (from httpx<1,>=0.23.0->huggingface_hub) (2025.10.5)\n",
      "Requirement already satisfied: h11>=0.16 in ./building_env/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->huggingface_hub) (0.16.0)\n",
      "Requirement already satisfied: click>=8.0.0 in ./building_env/lib/python3.10/site-packages (from typer-slim->huggingface_hub) (8.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in ./building_env/lib/python3.10/site-packages (from anyio->httpx<1,>=0.23.0->huggingface_hub) (1.3.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in ./building_env/lib/python3.10/site-packages (from anyio->httpx<1,>=0.23.0->huggingface_hub) (1.3.0)\n",
      "Collecting torchmetrics\n",
      "  Downloading torchmetrics-1.8.2-py3-none-any.whl (983 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m983.2/983.2 KB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: torch>=2.0.0 in ./building_env/lib/python3.10/site-packages (from torchmetrics) (2.9.0+cu128)\n",
      "Requirement already satisfied: packaging>17.1 in ./building_env/lib/python3.10/site-packages (from torchmetrics) (25.0)\n",
      "Requirement already satisfied: numpy>1.20.0 in ./building_env/lib/python3.10/site-packages (from torchmetrics) (2.1.2)\n",
      "Collecting lightning-utilities>=0.8.0\n",
      "  Downloading lightning_utilities-0.15.2-py3-none-any.whl (29 kB)\n",
      "Requirement already satisfied: typing_extensions in ./building_env/lib/python3.10/site-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.15.0)\n",
      "Requirement already satisfied: setuptools in ./building_env/lib/python3.10/site-packages (from lightning-utilities>=0.8.0->torchmetrics) (59.6.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in ./building_env/lib/python3.10/site-packages (from torch>=2.0.0->torchmetrics) (12.8.93)\n",
      "Requirement already satisfied: triton==3.5.0 in ./building_env/lib/python3.10/site-packages (from torch>=2.0.0->torchmetrics) (3.5.0)\n",
      "Requirement already satisfied: jinja2 in ./building_env/lib/python3.10/site-packages (from torch>=2.0.0->torchmetrics) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in ./building_env/lib/python3.10/site-packages (from torch>=2.0.0->torchmetrics) (2025.9.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in ./building_env/lib/python3.10/site-packages (from torch>=2.0.0->torchmetrics) (3.3)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in ./building_env/lib/python3.10/site-packages (from torch>=2.0.0->torchmetrics) (3.3.20)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in ./building_env/lib/python3.10/site-packages (from torch>=2.0.0->torchmetrics) (0.7.1)\n",
      "Requirement already satisfied: sympy>=1.13.3 in ./building_env/lib/python3.10/site-packages (from torch>=2.0.0->torchmetrics) (1.14.0)\n",
      "Requirement already satisfied: filelock in ./building_env/lib/python3.10/site-packages (from torch>=2.0.0->torchmetrics) (3.19.1)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in ./building_env/lib/python3.10/site-packages (from torch>=2.0.0->torchmetrics) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in ./building_env/lib/python3.10/site-packages (from torch>=2.0.0->torchmetrics) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in ./building_env/lib/python3.10/site-packages (from torch>=2.0.0->torchmetrics) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in ./building_env/lib/python3.10/site-packages (from torch>=2.0.0->torchmetrics) (1.13.1.3)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in ./building_env/lib/python3.10/site-packages (from torch>=2.0.0->torchmetrics) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in ./building_env/lib/python3.10/site-packages (from torch>=2.0.0->torchmetrics) (12.8.93)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in ./building_env/lib/python3.10/site-packages (from torch>=2.0.0->torchmetrics) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in ./building_env/lib/python3.10/site-packages (from torch>=2.0.0->torchmetrics) (2.27.5)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in ./building_env/lib/python3.10/site-packages (from torch>=2.0.0->torchmetrics) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in ./building_env/lib/python3.10/site-packages (from torch>=2.0.0->torchmetrics) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in ./building_env/lib/python3.10/site-packages (from torch>=2.0.0->torchmetrics) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in ./building_env/lib/python3.10/site-packages (from torch>=2.0.0->torchmetrics) (12.8.90)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./building_env/lib/python3.10/site-packages (from sympy>=1.13.3->torch>=2.0.0->torchmetrics) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./building_env/lib/python3.10/site-packages (from jinja2->torch>=2.0.0->torchmetrics) (2.1.5)\n",
      "Installing collected packages: lightning-utilities, torchmetrics\n",
      "Successfully installed lightning-utilities-0.15.2 torchmetrics-1.8.2\n",
      "Collecting accelerate>=1.1.0\n",
      "  Downloading accelerate-1.11.0-py3-none-any.whl (375 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m375.8/375.8 KB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pyyaml in ./building_env/lib/python3.10/site-packages (from accelerate>=1.1.0) (6.0.3)\n",
      "Requirement already satisfied: numpy>=1.17 in ./building_env/lib/python3.10/site-packages (from accelerate>=1.1.0) (2.1.2)\n",
      "Requirement already satisfied: psutil in ./building_env/lib/python3.10/site-packages (from accelerate>=1.1.0) (7.1.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in ./building_env/lib/python3.10/site-packages (from accelerate>=1.1.0) (0.6.2)\n",
      "Requirement already satisfied: packaging>=20.0 in ./building_env/lib/python3.10/site-packages (from accelerate>=1.1.0) (25.0)\n",
      "Requirement already satisfied: huggingface_hub>=0.21.0 in ./building_env/lib/python3.10/site-packages (from accelerate>=1.1.0) (1.0.0rc6)\n",
      "Requirement already satisfied: torch>=2.0.0 in ./building_env/lib/python3.10/site-packages (from accelerate>=1.1.0) (2.9.0+cu128)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in ./building_env/lib/python3.10/site-packages (from huggingface_hub>=0.21.0->accelerate>=1.1.0) (4.67.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in ./building_env/lib/python3.10/site-packages (from huggingface_hub>=0.21.0->accelerate>=1.1.0) (1.1.10)\n",
      "Requirement already satisfied: typer-slim in ./building_env/lib/python3.10/site-packages (from huggingface_hub>=0.21.0->accelerate>=1.1.0) (0.20.0)\n",
      "Requirement already satisfied: filelock in ./building_env/lib/python3.10/site-packages (from huggingface_hub>=0.21.0->accelerate>=1.1.0) (3.19.1)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in ./building_env/lib/python3.10/site-packages (from huggingface_hub>=0.21.0->accelerate>=1.1.0) (0.28.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./building_env/lib/python3.10/site-packages (from huggingface_hub>=0.21.0->accelerate>=1.1.0) (4.15.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./building_env/lib/python3.10/site-packages (from huggingface_hub>=0.21.0->accelerate>=1.1.0) (2025.9.0)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in ./building_env/lib/python3.10/site-packages (from torch>=2.0.0->accelerate>=1.1.0) (2.27.5)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in ./building_env/lib/python3.10/site-packages (from torch>=2.0.0->accelerate>=1.1.0) (1.13.1.3)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in ./building_env/lib/python3.10/site-packages (from torch>=2.0.0->accelerate>=1.1.0) (0.7.1)\n",
      "Requirement already satisfied: triton==3.5.0 in ./building_env/lib/python3.10/site-packages (from torch>=2.0.0->accelerate>=1.1.0) (3.5.0)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in ./building_env/lib/python3.10/site-packages (from torch>=2.0.0->accelerate>=1.1.0) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in ./building_env/lib/python3.10/site-packages (from torch>=2.0.0->accelerate>=1.1.0) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in ./building_env/lib/python3.10/site-packages (from torch>=2.0.0->accelerate>=1.1.0) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in ./building_env/lib/python3.10/site-packages (from torch>=2.0.0->accelerate>=1.1.0) (3.3.20)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in ./building_env/lib/python3.10/site-packages (from torch>=2.0.0->accelerate>=1.1.0) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in ./building_env/lib/python3.10/site-packages (from torch>=2.0.0->accelerate>=1.1.0) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in ./building_env/lib/python3.10/site-packages (from torch>=2.0.0->accelerate>=1.1.0) (12.8.93)\n",
      "Requirement already satisfied: networkx>=2.5.1 in ./building_env/lib/python3.10/site-packages (from torch>=2.0.0->accelerate>=1.1.0) (3.3)\n",
      "Requirement already satisfied: sympy>=1.13.3 in ./building_env/lib/python3.10/site-packages (from torch>=2.0.0->accelerate>=1.1.0) (1.14.0)\n",
      "Requirement already satisfied: jinja2 in ./building_env/lib/python3.10/site-packages (from torch>=2.0.0->accelerate>=1.1.0) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in ./building_env/lib/python3.10/site-packages (from torch>=2.0.0->accelerate>=1.1.0) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in ./building_env/lib/python3.10/site-packages (from torch>=2.0.0->accelerate>=1.1.0) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in ./building_env/lib/python3.10/site-packages (from torch>=2.0.0->accelerate>=1.1.0) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in ./building_env/lib/python3.10/site-packages (from torch>=2.0.0->accelerate>=1.1.0) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in ./building_env/lib/python3.10/site-packages (from torch>=2.0.0->accelerate>=1.1.0) (10.3.9.90)\n",
      "Requirement already satisfied: anyio in ./building_env/lib/python3.10/site-packages (from httpx<1,>=0.23.0->huggingface_hub>=0.21.0->accelerate>=1.1.0) (4.11.0)\n",
      "Requirement already satisfied: idna in ./building_env/lib/python3.10/site-packages (from httpx<1,>=0.23.0->huggingface_hub>=0.21.0->accelerate>=1.1.0) (3.11)\n",
      "Requirement already satisfied: certifi in ./building_env/lib/python3.10/site-packages (from httpx<1,>=0.23.0->huggingface_hub>=0.21.0->accelerate>=1.1.0) (2025.10.5)\n",
      "Requirement already satisfied: httpcore==1.* in ./building_env/lib/python3.10/site-packages (from httpx<1,>=0.23.0->huggingface_hub>=0.21.0->accelerate>=1.1.0) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in ./building_env/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->huggingface_hub>=0.21.0->accelerate>=1.1.0) (0.16.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./building_env/lib/python3.10/site-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate>=1.1.0) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./building_env/lib/python3.10/site-packages (from jinja2->torch>=2.0.0->accelerate>=1.1.0) (2.1.5)\n",
      "Requirement already satisfied: click>=8.0.0 in ./building_env/lib/python3.10/site-packages (from typer-slim->huggingface_hub>=0.21.0->accelerate>=1.1.0) (8.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in ./building_env/lib/python3.10/site-packages (from anyio->httpx<1,>=0.23.0->huggingface_hub>=0.21.0->accelerate>=1.1.0) (1.3.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in ./building_env/lib/python3.10/site-packages (from anyio->httpx<1,>=0.23.0->huggingface_hub>=0.21.0->accelerate>=1.1.0) (1.3.0)\n",
      "Installing collected packages: accelerate\n",
      "Successfully installed accelerate-1.11.0\n",
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.10.7-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m65.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting cycler>=0.10\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in ./building_env/lib/python3.10/site-packages (from matplotlib) (25.0)\n",
      "Collecting pyparsing>=3\n",
      "  Downloading pyparsing-3.2.5-py3-none-any.whl (113 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m113.9/113.9 KB\u001b[0m \u001b[31m54.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting contourpy>=1.0.1\n",
      "  Downloading contourpy-1.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (325 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m325.0/325.0 KB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pillow>=8 in ./building_env/lib/python3.10/site-packages (from matplotlib) (11.3.0)\n",
      "Collecting kiwisolver>=1.3.1\n",
      "  Downloading kiwisolver-1.4.9-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m58.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting fonttools>=4.22.0\n",
      "  Downloading fonttools-4.60.1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (4.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m65.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.7 in ./building_env/lib/python3.10/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: numpy>=1.23 in ./building_env/lib/python3.10/site-packages (from matplotlib) (2.1.2)\n",
      "Requirement already satisfied: six>=1.5 in ./building_env/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Installing collected packages: pyparsing, kiwisolver, fonttools, cycler, contourpy, matplotlib\n",
      "Successfully installed contourpy-1.3.2 cycler-0.12.1 fonttools-4.60.1 kiwisolver-1.4.9 matplotlib-3.10.7 pyparsing-3.2.5\n",
      "Collecting pycocotools\n",
      "  Downloading pycocotools-2.0.10-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (455 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m455.0/455.0 KB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy in ./building_env/lib/python3.10/site-packages (from pycocotools) (2.1.2)\n",
      "Installing collected packages: pycocotools\n",
      "Successfully installed pycocotools-2.0.10\n"
     ]
    }
   ],
   "source": [
    "# Install the necessary dependencies\n",
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu128 \n",
    "!pip install datasets\n",
    "!pip install evaluate \n",
    "!pip install albumentations\n",
    "!pip install git+https://github.com/huggingface/transformers.git\n",
    "\n",
    "# # We will use this to push our trained model to HF Hub\n",
    "!pip install huggingface_hub \n",
    "!pip install torchmetrics \n",
    "!pip install 'accelerate>=1.1.0'\n",
    "!pip install matplotlib\n",
    "!pip install pycocotools\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "026701d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tomas/Downloads/Siemens/building_env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Import the necessary packages\n",
    "import random\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from pathlib import Path\n",
    "from PIL import Image, ImageDraw\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import albumentations as A\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datasets import DatasetDict, Dataset, load_from_disk\n",
    "from transformers import (\n",
    "    Mask2FormerConfig,\n",
    "    Mask2FormerImageProcessor,\n",
    "    Mask2FormerModel,\n",
    "    Mask2FormerForUniversalSegmentation,\n",
    "    Trainer,\n",
    "    HfArgumentParser,\n",
    "    TrainingArguments,\n",
    ")\n",
    "from transformers.trainer import EvalPrediction\n",
    "from torchmetrics.detection.mean_ap import MeanAveragePrecision\n",
    "import evaluate\n",
    "from huggingface_hub import notebook_login\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Any, Optional\n",
    "import logging\n",
    "import transformers\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a45fac66",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b27a19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load COCO-style annotations from the 'buildings' dataset and convert to the Instance Segmentations format\n",
    "\n",
    "def coco2seg(dataset_dir, splits=['train', 'val', 'test']):\n",
    "    \"\"\"\n",
    "    Convert a COCO-style JSON (images, annotations, categories) to\n",
    "    a Instance Segmentation Dataset compatible format for Hugging Face Tasks.\n",
    "    \n",
    "    Args:\n",
    "        dataset_dir: path to the dataset\n",
    "        splits: splits to load and convert\n",
    "    \n",
    "    Returns:\n",
    "        DatasetDict object (!!!images saved as paths for memory usage!!!):\n",
    "            - 'image': PIL.Image\n",
    "            - 'annotation': PIL.Image with\n",
    "                            R channel = category_id\n",
    "                            G channel = instance_id (unique per image, <256 instances)\n",
    "    \"\"\"\n",
    "    dataset_dir = Path(dataset_dir)\n",
    "    result = {}\n",
    "\n",
    "    for split in splits:\n",
    "        ann_path = dataset_dir / f\"{split}/{split}_512.json\"\n",
    "        img_dir = dataset_dir / split / \"image_512\"\n",
    "\n",
    "        if not ann_path.exists() or not img_dir.exists():\n",
    "            if split == \"test\" and img_dir.exists():\n",
    "                print(f\"⚠️ No annotation file found for '{split}' — loading images only.\")\n",
    "                images = []\n",
    "                for f in img_dir.glob(\"*.tif\"):\n",
    "                    images.append({\"image\": str(f)})\n",
    "                \n",
    "                result[split] = Dataset.from_list(images)\n",
    "                continue\n",
    "            print(f\"WARNING: Missing split '{split}', skipping.\")\n",
    "            continue\n",
    "\n",
    "        print(f\"Processing split '{split}'...\")\n",
    "\n",
    "        # Load COCO annotation JSON\n",
    "        with open(ann_path, \"r\") as f:\n",
    "            coco = json.load(f)\n",
    "\n",
    "        images = {img[\"id\"]: img for img in coco[\"images\"]}\n",
    "        annotations = coco[\"annotations\"]\n",
    "\n",
    "        # Group annotations by image_id\n",
    "        anns_by_img = {}\n",
    "        for ann in annotations:\n",
    "            anns_by_img.setdefault(ann[\"image_id\"], []).append(ann)\n",
    "\n",
    "        records = []\n",
    "        for img_id, img_info in tqdm(images.items()):\n",
    "            file_name = Path(img_info[\"file_name\"]).name\n",
    "            \n",
    "            width, height = img_info[\"width\"], img_info[\"height\"]\n",
    "\n",
    "            image_path = img_dir / file_name\n",
    "\n",
    "            if not image_path.exists():\n",
    "                continue\n",
    "\n",
    "            # Create blank annotation image (2-channel RGB)\n",
    "            ann_img = np.zeros((height, width, 3), dtype=np.uint8)\n",
    "\n",
    "            # Draw polygons per instance\n",
    "            r = Image.new(\"L\", (width, height), 0)  # Category\n",
    "            g = Image.new(\"L\", (width, height), 0)  # Instance\n",
    "            draw_r = ImageDraw.Draw(r)\n",
    "            draw_g = ImageDraw.Draw(g)\n",
    "\n",
    "            anns = anns_by_img.get(img_id, [])\n",
    "            instance_counter = 1\n",
    "            cat_ids = []\n",
    "            for ann in anns:\n",
    "                \n",
    "                cat_id = int(ann[\"category_id\"])\n",
    "                cat_ids.append(cat_id)\n",
    "                polygons = ann.get(\"segmentation\", [])\n",
    "                if not polygons or not isinstance(polygons, list):\n",
    "                    continue\n",
    "\n",
    "                # Each polygon in COCO is a list of [x1, y1, x2, y2, ...]\n",
    "                for poly in polygons:\n",
    "                    if len(poly) < 6:  # invalid polygon\n",
    "                        continue\n",
    "                    xy = [(poly[i], poly[i + 1]) for i in range(0, len(poly), 2)]\n",
    "                    draw_r.polygon(xy, fill=cat_id+1)\n",
    "                    draw_g.polygon(xy, fill=instance_counter)\n",
    "\n",
    "                instance_counter += 1\n",
    "                if instance_counter >= 256:\n",
    "                    print(f\"WARNING: Too many instances in {file_name}, clipping to 255.\")\n",
    "                    break\n",
    "\n",
    "            # Merge R and G channels back into RGB\n",
    "            ann_img = np.stack([\n",
    "                np.array(r), \n",
    "                np.array(g), \n",
    "                np.zeros((height, width), np.uint8)], \n",
    "                axis=-1)\n",
    "\n",
    "            # SAVE AS PNG SUPER IMPORTANT FOR NO DATA LOSS\n",
    "            ann_path = dataset_dir / split / \"annotation\" / f\"{Path(img_info['file_name']).stem}.png\"\n",
    "            ann_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "            ann_img = ann_img.astype(np.uint8)\n",
    "            Image.fromarray(ann_img).save(ann_path)\n",
    "\n",
    "            records.append({\n",
    "                \"image\": str(image_path),\n",
    "                \"annotation\": str(ann_path)\n",
    "            })\n",
    "\n",
    "        result[split] = Dataset.from_list(records)\n",
    "\n",
    "    dataset = DatasetDict(result)\n",
    "\n",
    "    dataset.save_to_disk(dataset_dir / \"hf\")\n",
    "\n",
    "    return dataset\n",
    "\n",
    "DATASET_DIR = Path(\"./building-extraction-generalization-2024\")\n",
    "\n",
    "dataset = coco2seg(DATASET_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b8da9196",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1000 examples [00:00, 23452.30 examples/s]\n",
      "Map: 100%|██████████| 3784/3784 [00:01<00:00, 2212.73 examples/s]ards/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 4/4 [00:00<00:00, 10.56ba/s]\n",
      "Processing Files (1 / 1): 100%|██████████|  288MB /  288MB,  237MB/s  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  \u001b[2m2025-10-20T15:41:38.032081Z\u001b[0m \u001b[33m WARN\u001b[0m  \u001b[33mStatus Code: 500. Retrying..., \u001b[1;33mrequest_id\u001b[0m\u001b[33m: \"\"\u001b[0m\n",
      "    \u001b[2;3mat\u001b[0m /home/runner/work/xet-core/xet-core/cas_client/src/http_client.rs:227\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Files (1 / 1): 100%|██████████|  288MB /  288MB, 33.0MB/s  \n",
      "New Data Upload: |          |  0.00B /  0.00B,  0.00B/s  \n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:14<00:00, 14.08s/ shards]\n",
      "Map: 100%|██████████| 933/933 [00:00<00:00, 2094.86 examples/s]shards/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00,  9.77ba/s]\n",
      "Processing Files (1 / 1): 100%|██████████| 71.4MB / 71.4MB, 52.8MB/s  \n",
      "New Data Upload: |          |  0.00B /  0.00B,  0.00B/s  \n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:02<00:00,  2.73s/ shards]\n",
      "Map: 100%|██████████| 250/250 [00:00<00:00, 283.20 examples/s] shards/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 4/4 [00:00<00:00,  5.14ba/s]\n",
      "Processing Files (0 / 1):  90%|█████████ |  348MB /  387MB, 6.56MB/s  \n",
      "New Data Upload: 100%|██████████|  117MB /  117MB, 4.01MB/s  \n",
      "Map: 100%|██████████| 250/250 [00:00<00:00, 449.36 examples/s]3, 27.96s/ shards]\n",
      "Creating parquet from Arrow format: 100%|██████████| 4/4 [00:00<00:00,  5.92ba/s]\n",
      "Processing Files (0 / 1):  89%|████████▉ |  348MB /  391MB, 22.1MB/s  \n",
      "New Data Upload: 100%|██████████|  121MB /  121MB, 9.06MB/s  \n",
      "Map: 100%|██████████| 250/250 [00:00<00:00, 553.89 examples/s]7, 23.63s/ shards]\n",
      "Creating parquet from Arrow format: 100%|██████████| 4/4 [00:00<00:00,  5.04ba/s]\n",
      "Processing Files (0 / 1):  90%|█████████ |  346MB /  384MB, 14.4MB/s  \n",
      "New Data Upload: 100%|██████████|  120MB /  120MB, 10.7MB/s  \n",
      "Map: 100%|██████████| 250/250 [00:00<00:00, 460.98 examples/s]1, 21.69s/ shards]\n",
      "Creating parquet from Arrow format: 100%|██████████| 4/4 [00:00<00:00,  4.31ba/s]\n",
      "Processing Files (0 / 1):  87%|████████▋ |  324MB /  374MB, 35.2MB/s  \n",
      "New Data Upload: 100%|██████████|  110MB /  110MB, 13.1MB/s  \n",
      "Uploading the dataset shards: 100%|██████████| 4/4 [01:23<00:00, 20.98s/ shards]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/tomascanivari/building_extraction/commit/3cda4b2efb754cb0d17ce56e1f500fa99aa971b1', commit_message='Upload dataset', commit_description='', oid='3cda4b2efb754cb0d17ce56e1f500fa99aa971b1', pr_url=None, repo_url=RepoUrl('https://huggingface.co/datasets/tomascanivari/building_extraction', endpoint='https://huggingface.co', repo_type='dataset', repo_id='tomascanivari/building_extraction'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Upload Dataset to Hugging Face HUB\n",
    "from datasets import Dataset, Features, Image as ImageHF\n",
    "from huggingface_hub import login\n",
    "\n",
    "login('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') \n",
    "\n",
    "import glob\n",
    "from PIL import Image\n",
    "\n",
    "# --- Define generator factory functions ---\n",
    "def make_gen_examples_train_val(images, annotations):\n",
    "    def gen():\n",
    "        for img_path, ann_path in zip(images, annotations):\n",
    "            yield {\n",
    "                \"image\": {\"path\": img_path},\n",
    "                \"annotation\": {\"path\": ann_path},\n",
    "            }\n",
    "    return gen\n",
    "\n",
    "# --- Define consistent feature schemas ---\n",
    "features = Features({\n",
    "    \"image\": ImageHF(),\n",
    "    \"annotation\": ImageHF()\n",
    "})\n",
    "\n",
    "\n",
    "# --- Build each split independently ---\n",
    "# Train\n",
    "train_images = sorted(glob.glob(\"./building-extraction-generalization-2024/train/image_512/*.jpg\"))\n",
    "train_anns = sorted(glob.glob(\"./building-extraction-generalization-2024/train/annotation/*.png\"))\n",
    "train_ds = Dataset.from_generator(make_gen_examples_train_val(train_images, train_anns),\n",
    "                                  features=features)\n",
    "\n",
    "# Validation\n",
    "val_images = sorted(glob.glob(\"./building-extraction-generalization-2024/val/image_512/*.jpg\"))\n",
    "val_anns = sorted(glob.glob(\"./building-extraction-generalization-2024/val/annotation/*.png\"))\n",
    "val_ds = Dataset.from_generator(make_gen_examples_train_val(val_images, val_anns),\n",
    "                                features=features)\n",
    "\n",
    "# Test\n",
    "test_images = sorted(glob.glob(\"./building-extraction-generalization-2024/test/image_512/*.tif\"))\n",
    "test_anns = sorted(glob.glob(\"./building-extraction-generalization-2024/test/image_512/*.tif\"))\n",
    "test_ds = Dataset.from_generator(make_gen_examples_train_val(test_images, test_anns),\n",
    "                                 features=features)\n",
    "\n",
    "\n",
    "ds_dict = DatasetDict({\"train\": train_ds, \"val\": val_ds, \"test\": test_ds})\n",
    "ds_dict.push_to_hub(\"tomascanivari/building_extraction\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6d6b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "# Load Converted Dataset\n",
    "DATASET_HF_DIR = \"tomascanivari/building_extraction\"\n",
    "\n",
    "dataset = load_dataset(\"tomascanivari/building_extraction\")\n",
    "\n",
    "print(dataset)\n",
    "\n",
    "# Let's check first train image and annotation\n",
    "example = dataset[\"train\"][0]\n",
    "img = example[\"image\"]\n",
    "ann = example[\"annotation\"]\n",
    "\n",
    "# Load PIL image\n",
    "image = np.array(img.convert(\"RGB\"))\n",
    "annotation = np.array(ann)\n",
    "\n",
    "print(\"Number of Categories: \", np.unique(annotation[..., 0]))  # Red channel: category IDs\n",
    "print(\"Number of Instances: \", np.unique(annotation[..., 1]))  # Green channel: instance IDs\n",
    "\n",
    "# Plot the original image and the annotations\n",
    "plt.figure(figsize=(15, 5))\n",
    "for plot_index in range(3):\n",
    "    if plot_index == 0:\n",
    "        # If plot index is 0 display the original image\n",
    "        plot_image = image\n",
    "        title = \"Original\"\n",
    "    else:\n",
    "        # Else plot the annotation maps\n",
    "        plot_image = annotation[..., plot_index - 1]\n",
    "        title = [\"Class Map (R)\", \"Instance Map (G)\"][plot_index - 1]\n",
    "    # Plot the image\n",
    "    plt.subplot(1, 3, plot_index + 1)\n",
    "    plt.imshow(plot_image)\n",
    "    plt.title(title)\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "# Let' check instance 0\n",
    "print(\"Instance 1\")\n",
    "mask = (annotation[..., 1] == 1)\n",
    "visual_mask = (mask * 255).astype(np.uint8)\n",
    "Image.fromarray(visual_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52999be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (MaskFormerConfig, MaskFormerForInstanceSegmentation, MaskFormerImageProcessor)\n",
    "\n",
    "# Change label2id and id2label (Start from 0, when in annotations it starts from 1. Compatible with reduce in Processor)\n",
    "id2label = {0: 'building'}\n",
    "label2id = {'building': 0}\n",
    "\n",
    "# Load pre-trained weights\n",
    "model = MaskFormerForInstanceSegmentation.from_pretrained(\"facebook/maskformer-swin-base-coco\", id2label=id2label,\n",
    "                                                          ignore_mismatched_sizes=True)\n",
    "# Load processor\n",
    "processor = MaskFormerImageProcessor(\n",
    "    do_reduce_labels=True,\n",
    "    size=(512, 512),\n",
    "    ignore_index=255,\n",
    "    do_resize=False,\n",
    "    do_rescale=False,\n",
    "    do_normalize=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e2a851",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset # To make ImageSegmentationDataset a PyTorch dataset !!!!!!!!!!!!!!!!\n",
    "\n",
    "# Define the configurations of the transforms specific\n",
    "# to the dataset used\n",
    "ADE_MEAN = np.array([123.675, 116.280, 103.530]) / 255\n",
    "ADE_STD = np.array([58.395, 57.120, 57.375]) / 255\n",
    "# Build the augmentation transforms\n",
    "train_val_transform = A.Compose([\n",
    "    A.Resize(width=512, height=512),\n",
    "    A.HorizontalFlip(p=0.3),\n",
    "    A.Normalize(mean=ADE_MEAN, std=ADE_STD),\n",
    "    A.ToFloat()\n",
    "])\n",
    "\n",
    "class ImageSegmentationDataset(Dataset):\n",
    "    def __init__(self, dataset, processor, transform=None):\n",
    "        # Initialize the dataset, processor, and transform variables\n",
    "        self.dataset = dataset\n",
    "        self.processor = processor\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        # Return the number of datapoints\n",
    "        return len(self.dataset)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Convert the PIL Image to a NumPy array\n",
    "        image = np.array(self.dataset[idx][\"image\"].convert(\"RGB\"))\n",
    "\n",
    "        # Get the pixel wise instance id and category id maps\n",
    "        # of shape (height, width)\n",
    "        annotation = np.array(self.dataset[idx][\"annotation\"])\n",
    "        instance_seg = np.array(annotation)[..., 1]\n",
    "        class_id_map = np.array(annotation)[..., 0]\n",
    "        class_labels = np.unique(class_id_map)\n",
    "        \n",
    "        # Build the instance to class dictionary\n",
    "        inst2class = {}\n",
    "        for label in class_labels:\n",
    "            instance_ids = np.unique(instance_seg[class_id_map == label])\n",
    "            inst2class.update({i: label for i in instance_ids})\n",
    "        # Apply transforms\n",
    "        if self.transform is not None:\n",
    "            transformed = self.transform(image=image, mask=instance_seg)\n",
    "            (image, instance_seg) = (transformed[\"image\"], transformed[\"mask\"])\n",
    "            \n",
    "            # Convert from channels last to channels first\n",
    "            image = image.transpose(2,0,1)\n",
    "        if class_labels.shape[0] == 1 and class_labels[0] == 0:\n",
    "            # If the image has no objects then it is skipped\n",
    "            inputs = self.processor([image], return_tensors=\"pt\")\n",
    "            inputs = {k:v.squeeze() for k,v in inputs.items()}\n",
    "            inputs[\"class_labels\"] = torch.tensor([0])\n",
    "            inputs[\"mask_labels\"] = torch.zeros(\n",
    "                (0, inputs[\"pixel_values\"].shape[-2], inputs[\"pixel_values\"].shape[-1])\n",
    "            )\n",
    "        else:\n",
    "            # Else use process the image with the segmentation maps\n",
    "            inputs = self.processor(\n",
    "                [image],\n",
    "                [instance_seg],\n",
    "                instance_id_to_semantic_id=inst2class,\n",
    "                return_tensors=\"pt\"\n",
    "            )\n",
    "            inputs = {\n",
    "                k:v.squeeze() if isinstance(v, torch.Tensor) else v[0] for k,v in inputs.items()\n",
    "            }\n",
    "        # Return the inputs\n",
    "        return inputs\n",
    "\n",
    "# Build the train and validation instance segmentation dataset\n",
    "train_dataset = ImageSegmentationDataset(\n",
    "    dataset[\"train\"],\n",
    "    processor=processor,\n",
    "    transform=train_val_transform\n",
    ")\n",
    "val_dataset = ImageSegmentationDataset(\n",
    "    dataset[\"val\"],\n",
    "    processor=processor,\n",
    "    transform=train_val_transform\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1090b4e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if everything is preprocessed correctly\n",
    "print(\"Train Instance 0\")\n",
    "inputs = train_dataset[0]\n",
    "for k,v in inputs.items():\n",
    "  print(k, v.shape)\n",
    "\n",
    "print(\"\\nTrain Instance 1\")\n",
    "inputs = train_dataset[1]\n",
    "for k,v in inputs.items():\n",
    "  print(k, v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335da94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    pixel_values = torch.stack([example[\"pixel_values\"] for example in batch])\n",
    "    pixel_mask = torch.stack([example[\"pixel_mask\"] for example in batch])\n",
    "    class_labels = [example[\"class_labels\"] for example in batch]\n",
    "    mask_labels = [example[\"mask_labels\"] for example in batch]\n",
    "    return {\"pixel_values\": pixel_values, \"pixel_mask\": pixel_mask, \"class_labels\": class_labels, \"mask_labels\": mask_labels}\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=1, \n",
    "    shuffle=True, \n",
    "    collate_fn=collate_fn)\n",
    "\n",
    "val_dataloader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=1, \n",
    "    shuffle=False, \n",
    "    collate_fn=collate_fn,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a285b20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if batching is correct\n",
    "batch = next(iter(train_dataloader))\n",
    "for k,v in batch.items():\n",
    "  if isinstance(v, torch.Tensor):\n",
    "    print(k,v.shape)\n",
    "  else:\n",
    "    print(k,len(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097c4a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model(\n",
    "          pixel_values=batch[\"pixel_values\"],\n",
    "          mask_labels=batch[\"mask_labels\"],\n",
    "          class_labels=batch[\"class_labels\"],\n",
    "      )\n",
    "outputs.loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ec2d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device(\"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Initialize Adam optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=5e-5)\n",
    "\n",
    "# Set number of epochs and batch size\n",
    "num_epochs = 2\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch {epoch} | Training\")\n",
    "    \n",
    "    # Set model in training mode \n",
    "    model.train()\n",
    "    train_loss, val_loss = [], []\n",
    "    \n",
    "    \n",
    "    # Training loop\n",
    "    for idx, batch in enumerate(tqdm(train_dataloader)):\n",
    "        # Reset the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(\n",
    "            pixel_values=batch[\"pixel_values\"].to(device),\n",
    "            mask_labels=[labels.to(device) for labels in batch[\"mask_labels\"]],\n",
    "            class_labels=[labels.to(device) for labels in batch[\"class_labels\"]],\n",
    "        )\n",
    "        # Backward propagation\n",
    "        loss = outputs.loss\n",
    "        train_loss.append(loss.item())\n",
    "        loss.backward()\n",
    "        # if idx % 50 == 0:\n",
    "            # print(\"  Training loss: \", round(sum(train_loss)/len(train_loss), 6))\n",
    "        \n",
    "        # Optimization\n",
    "        optimizer.step()\n",
    "    \n",
    "    # Average train epoch loss\n",
    "    train_loss = sum(train_loss)/len(train_loss)\n",
    "    \n",
    "    # Set model in evaluation mode\n",
    "    model.eval()\n",
    "    start_idx = 0\n",
    "    print(f\"Epoch {epoch} | Validation\")\n",
    "    for idx, batch in enumerate(tqdm(val_dataloader)):\n",
    "        with torch.no_grad():\n",
    "            # Forward pass\n",
    "            outputs = model(\n",
    "                pixel_values=batch[\"pixel_values\"].to(device),\n",
    "                mask_labels=[labels.to(device) for labels in batch[\"mask_labels\"]],\n",
    "                class_labels=[labels.to(device) for labels in batch[\"class_labels\"]],\n",
    "            )\n",
    "            # Get validation loss\n",
    "            loss = outputs.loss\n",
    "            val_loss.append(loss.item())\n",
    "            # if idx % 50 == 0:\n",
    "                # print(\"  Validation loss: \", round(sum(val_loss)/len(val_loss), 6))\n",
    "    \n",
    "    # Average validation epoch loss\n",
    "    val_loss = sum(val_loss)/len(val_loss)\n",
    "    \n",
    "    # Print epoch losses\n",
    "    print(f\"Epoch {epoch} | train_loss: {train_loss} | validation_loss: {val_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c178556",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save_pretrained(\"models/mf\")\n",
    "# processor.save_pretrained(\"models/mf_p\")\n",
    "from transformers import MaskFormerForInstanceSegmentation, MaskFormerImageProcessor\n",
    "\n",
    "model = MaskFormerForInstanceSegmentation.from_pretrained(\"models/mf\")\n",
    "processor = MaskFormerImageProcessor.from_pretrained(\"models/mf_p\")\n",
    "\n",
    "# We won't be using albumentations to preprocess images for inference\n",
    "processor.do_normalize = True\n",
    "processor.do_resize = True\n",
    "processor.do_rescale = True\n",
    "\n",
    "# Push your model and preprocessor to the Hub\n",
    "model.push_to_hub(\"maskformer-swin-base-building-instance\")\n",
    "processor.push_to_hub(\"maskformer-swin-base-building-instance\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BuildingEnv",
   "language": "python",
   "name": "building_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
